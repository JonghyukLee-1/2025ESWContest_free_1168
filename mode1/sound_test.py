import numpy as np
import os
import sys
import time
import RPi.GPIO as GPIO
import sounddevice as sd
import librosa
import joblib
from scipy.signal import butter, sosfiltfilt
from typing import Tuple

# --- ì „ì—­ ì„¤ì • (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ì„¤ì •) ---
SAMPLE_RATE = 48000
CHANNELS = 2
SOLENOID_GPIO_PIN = 17
MODEL_FILE = "one_class_svm_classifier.joblib"
MIC_DEVICE_NAME = 'snd_rpi_googlevoicehat_soundcar'
BP_LOW = 1000.0
BP_HIGH = 4500.0
CLIP_DURATION_SEC = 5.0
N_MFCC = 20
THRESHOLD = 0.5

# --- DSP ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼) ---
def butter_bandpass_sos(low_cut: float, high_cut: float, fs: int, order: int = 4):
    nyq = 0.5 * fs
    return butter(order, [low_cut / nyq, high_cut / nyq], btype='band', output='sos')

def gcc_phat(sig: np.ndarray, ref: np.ndarray, fs: int, max_tau: float | None = None) -> float:
    n = 1
    L = len(sig) + len(ref)
    while n < L:
        n <<= 1
    SIG = np.fft.rfft(sig, n=n)
    REF = np.fft.rfft(ref, n=n)
    R = SIG * np.conj(REF)
    R /= np.abs(R) + 1e-12
    cc = np.fft.irfft(R, n=n)
    max_shift = int(n // 2)
    if max_tau is not None:
        max_shift = min(max_shift, int(max_tau * fs))
    cc = np.concatenate((cc[-max_shift:], cc[:max_shift + 1]))
    shift = np.argmax(np.abs(cc)) - max_shift
    return shift / fs

def align_by_delay(x: np.ndarray, y: np.ndarray, fs: int, tau: float) -> Tuple[np.ndarray, np.ndarray]:
    shift = int(round(tau * fs))
    if shift > 0:
        y2 = np.concatenate([y[shift:], np.zeros(shift, dtype=y.dtype)])
    elif shift < 0:
        y2 = np.concatenate([np.zeros(-shift, dtype=y.dtype), y[:shift]])
    else:
        y2 = y.copy()
    n = min(len(x), len(y2))
    return x[:n], y2[:n]

def estimate_alpha(front: np.ndarray, rear: np.ndarray, fs: int) -> float:
    pre_s = 1
    pre_samples = int(pre_s * fs)
    if pre_samples >= len(front) or pre_samples >= len(rear):
        return 1.0
    f = front[:pre_samples]
    r = rear[:pre_samples]
    den = np.dot(r, r) + 1e-9
    return float(np.clip(np.dot(f, r) / den, 0.0, 1.0))

# --- ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ë¡œ ë³€ê²½ ---
def extract_spectral_centroid_features(audio_data, sr):
    if audio_data.size == 0:
        return np.zeros((1, 1))
    
    spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=sr, hop_length=128)
    return spectral_centroids.flatten()

def normalize_features(features: np.ndarray) -> np.ndarray:
    """íŠ¹ì§• ë°°ì—´ì„ 0ê³¼ 1 ì‚¬ì´ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    min_val = np.min(features)
    max_val = np.max(features)
    if (max_val - min_val) > 0:
        normalized_features = (features - min_val) / (max_val - min_val)
    else:
        normalized_features = np.zeros_like(features)
    return normalized_features

# --- ì†”ë ˆë…¸ì´ë“œ ì œì–´ í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼) ---
def activate_solenoid():
    GPIO.output(SOLENOID_GPIO_PIN, GPIO.HIGH)
    time.sleep(0.1)
    GPIO.output(SOLENOID_GPIO_PIN, GPIO.LOW)

# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---
def main_run_process():
    try:
        model = joblib.load(MODEL_FILE)

        # GPIO ì„¤ì •
        GPIO.setmode(GPIO.BCM)
        GPIO.setup(SOLENOID_GPIO_PIN, GPIO.OUT)

        # ë§ˆì´í¬ ì¥ì¹˜ ì¸ë±ìŠ¤ ì°¾ê¸°
        device_index = None
        for i, device in enumerate(sd.query_devices()):
            if MIC_DEVICE_NAME in device['name']:
                device_index = i
                break
        if device_index is None:
            print(f"[ì˜¤ë¥˜] '{MIC_DEVICE_NAME}' ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)

        print("[INFO] ì‹¤ì‹œê°„ íƒ€ì¼ ì¶”ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤. 'Enter' í‚¤ë¥¼ ëˆ„ë¥´ë©´ íƒ€ê²© ë° ì¶”ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        input("ì¤€ë¹„ë˜ë©´ Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")

        frames = []
        with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, device=device_index, dtype='float32') as stream:
            print("-> íƒ€ê²©ìŒì„ ë…¹ìŒí•©ë‹ˆë‹¤...")
            start_time = time.time()
            solenoid_triggered = False

            while True:
                data, overflowed = stream.read(1024)
                frames.append(data.copy())
                current_rec_time = time.time() - start_time
                
                if current_rec_time > 1.0 and not solenoid_triggered:
                    activate_solenoid()
                    solenoid_triggered = True

                if current_rec_time > 1.0 + CLIP_DURATION_SEC:
                    break
        
        recording = np.concatenate(frames)
        left_audio = recording[:, 0]
        right_audio = recording[:, 1]
        
        # --- ì „ì²˜ë¦¬ ê³¼ì • ---
        gain_factor = estimate_alpha(right_audio, left_audio, SAMPLE_RATE)
        tau = gcc_phat(left_audio, right_audio, SAMPLE_RATE, max_tau=0.010)
        right_aligned, left_aligned = align_by_delay(right_audio, left_audio, SAMPLE_RATE, tau)
        sos = butter_bandpass_sos(BP_LOW, BP_HIGH, SAMPLE_RATE)
        right_bp = sosfiltfilt(sos, right_aligned)
        left_bp = sosfiltfilt(sos, left_aligned)
        clean_audio = right_bp - gain_factor * left_bp

        # ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬ íŠ¹ì§• ì¶”ì¶œ
        features = extract_spectral_centroid_features(clean_audio, SAMPLE_RATE)
        
        # ì •ê·œí™”
        normalized_features = normalize_features(features)
        
        # ëª¨ë¸ì— ë§ëŠ” ê¸¸ì´ë¡œ íŒ¨ë”©
        # `train_oneclass.py` ì‹¤í–‰ í›„ ì¶œë ¥ë˜ëŠ” 'ê°€ì¥ ê¸´ ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬ íŠ¹ì§• ê¸¸ì´'ë¡œ ë³€ê²½
        fixed_length = 1841 # <-- ì´ ê°’ì„ ìƒˆë¡œìš´ ê°’ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!
        
        if len(normalized_features) > fixed_length:
            final_features = normalized_features[:fixed_length]
        else:
            pad_width = fixed_length - len(normalized_features)
            final_features = np.pad(normalized_features, (0, pad_width), 'constant')
            
        final_features = final_features.reshape(1, -1)

        # ëª¨ë¸ ì¶”ë¡ 
        score = model.score_samples(final_features)
        
        print("\n--- ì¶”ë¡  ê²°ê³¼ ---")
        print(f"-> ì´ìƒ íƒ€ì¼ ìœ ì‚¬ë„ ì ìˆ˜: {score[0]:.4f}")
        
        if score[0] > THRESHOLD:
            print("-> ì´ íƒ€ì¼ì€ 'ì´ìƒ'ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. ğŸš¨")
        else:
            print("-> ì´ íƒ€ì¼ì€ 'ì •ìƒ'ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. âœ…")

    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    finally:
        GPIO.cleanup()

if __name__ == "__main__":
    main_run_process()
